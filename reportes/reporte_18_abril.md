### **Jorge Mario Trejos Barquero.**
### **B77676.**

#### **Resumen**
En estas 2 primeras semanas de clases se ha hablado de diversos temas, a continuación se hará una clasificación de ellos.

##### 1) Introducción al curso
En esta parte del curso se habló de la definición de algunos términos que están relacionados con el curso, algunos tales como: datos, información, mina, minería, etc. Se habló de que big data no es algo nuevo del todo ya que, es una combinación de conocimiento viejo y nuevo, viejo como machine learning y análisis de datos y nuevo por todo el hardware y software que a evolucionado a través de los años. Se hizo mención a que el término de biga data no esta del todo bien definido pero que hay 3 características que se le atribuyen, estas son: volumen. veracidad y velocidad.

##### 2) Sistematización del proceso de minería de datos
Se habló del proceso que se sigue normalmente para la minería de datos, este es:
1) Limpieza de los datos. 
2) Integración de diferentes fuentes de datos. 
3) Selección de datos representativos. 
4) Transformación. 
5) Proceso de minería con estrategias. 
6) Evaluación 
7) Presentación de los datos. 

Luego se mencionaron algunos de los retos que tiene este proceso, tales como: escalabilidad, dimensionalidad, heterogeneidad de los datos, inconsistencia de los datos, temporalidad, etc.

##### 3) Collecting data
De donde y como obtengo los datos que se van a analizar. Dentro de este aspecto hay que mencionar que los datos tienen que ser confiables, tratados con cuidado y que se deben de trabajar antes de realizar cualquier análisis. Trabajar los datos significa reducir o eliminar el ruido que pueda haber en ellos, el ruido puede ser corregible (artifacts) o no corregible. Para corregir un poco de ruido hay múltiples técnicas, una de ellas de las que se vieron en clase es la técnica del vecino más cercano, donde para un valor faltante se le pone el del vecino más cercano. Existen valores de tipo numéricos y categóricos, además de valores atípicos los cuales pueden sesgar nuestros resultados

##### 4) Exploración de los datos
Finalmente, se habló de la exploración de los datos, este es un proceso de análisis donde se somete el dataset ya limpiado a varios test para poder aceptar o rechazar las hipótesis realizadas. Es importante no torturar el dataset, esto significa no someterlo a muchas hipótesis y test ya que se puede perderse el objetivo principal del análisis y puede dar paso a problemas como correlaciones falses donde dos variables sin relación alguna parecen tener alguna clase de interacción. Para iniciar este proceso hay que conocer muy bien el dataset y 5 valores muy importantes a conocer para cada variable los cuales nos pueden dar mucha información son: mínimo, primer cuartil, mediana, tercer cuartil y máximo.

#### **Aprendido**
Sobre todo lo aprendido gira más entorno a las definiciones que tienen que ver con big data como tal ya que, toda la parte de colecta de datos y análisis exploratorio ya son temas que se vieron en el curso de diseño de experimentos para los estudiantes que pertenecieran al énfasis de TI o CC.

#### **Dudas**
En general las dudas que me han surgido son más referentes a las herramientas y formatos tales como jupyterlab y markdown por ejemplo ya que nunca los he usado hasta el momento, entonces voy aprendiendo a como los voy usando e investigando

#### **Uso en el futuro**
Uno de mis trabajos deseados en el futuro sería analizar datos, por esta razón todo lo que se vio en estás primeras 2 semanas de clases me parece interesante y útil para lo que me gustaría hacer cuando trabaje.

#### **Material extra**
Para esta primera parte del curso no se consulto ninguna fuente de información externa, solo lo hablado en clase y la matería vista en el curso anteriormente mencionado de diseño de experimentos.